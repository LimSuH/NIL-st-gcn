{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from turtle import color\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import mmcv\n",
    "from mmpose.apis import (collect_multi_frames, inference_top_down_pose_model,\n",
    "                         init_pose_model, process_mmdet_results, vis_pose_result)\n",
    "from mmpose.datasets import DatasetInfo\n",
    "from mmdet.apis import inference_detector, init_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector config and checkpoint\n",
    "det_config = '/home/lab/mmpose/demo/mmdetection_cfg/ssdlite_mobilenetv2_scratch_600e_onehand.py'\n",
    "det_checkpoint = '/home/lab/.cache/torch/hub/checkpoints/det/ssdlite_mobilenetv2_scratch_600e_onehand-4f9f8686_20220523.pth'\n",
    "det_checkpoint_url = 'https://download.openmmlab.com/mmpose/mmdet_pretrained/ssdlite_mobilenetv2_scratch_600e_onehand-4f9f8686_20220523.pth'\n",
    "\n",
    "# hand keypoint estimator config and checkpoint\n",
    "hand_config ='/home/lab/mmpose/configs/hand/2d_kpt_sview_rgb_img/topdown_heatmap/rhd2d/hrnetv2_w18_rhd2d_256x256.py'\n",
    "hand_checkpoint = '/home/lab/.cache/torch/hub/checkpoints/hand/hrnetv2_w18_rhd2d_256x256-95b20dd8_20210330.pth'\n",
    "hand_checkpoint_url = 'https://download.openmmlab.com/mmpose/hand/hrnetv2/hrnetv2_w18_rhd2d_256x256-95b20dd8_20210330.pth'\n",
    "\n",
    "# other arguments\n",
    "args_show = False\n",
    "args_out_video_root = ''\n",
    "args_device = 'cuda:0'\n",
    "args_det_cat_id = 1\n",
    "args_bbox_thr = 0.3\n",
    "args_kpt_thr = 0.3\n",
    "args_radius = 3\n",
    "args_thickness = 1\n",
    "args_use_multi_frames = False\n",
    "args_online = False\n",
    "\n",
    "\n",
    "# build the detection model from a config file and a checkpoint file\n",
    "det_model = init_detector(det_config, det_checkpoint, device=args_device)\n",
    "hand_model = init_pose_model(hand_config, hand_checkpoint, device=args_device)\n",
    "    \n",
    "# get dataset info\n",
    "hand_dataset = hand_model.cfg.data['test']['type']\n",
    "hand_dataset_info = hand_model.cfg.data['test'].get('dataset_info', None)\n",
    "hand_dataset_info = DatasetInfo(hand_dataset_info)\n",
    "\n",
    "# input and output paths\n",
    "AUTSL_PATH = '/dataset/AUTSL'\n",
    "KETI_PATH = '/dataset/KETI_SignLanguage/Video'\n",
    "    \n",
    "AUTSL_DIR = ['/dataset/AUTSL/train', '/dataset/AUTSL/test', '/dataset/AUTSL/val']\n",
    "KETI_DIR = [os.path.join(KETI_PATH, dir) for dir in natsorted(os.listdir(KETI_PATH))]\n",
    "\n",
    "AUTSL_max = 120\n",
    "KETI_max = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_detect(whole_stop, dataset):\n",
    "    videos = natsorted(os.listdir(dataset))\n",
    "    #_____________________________\n",
    "    #videos = videos[:1]\n",
    "    #____________________________\n",
    "\n",
    "    print(f'Total {len(videos)} files are being pose-estimated...')\n",
    "\n",
    "    for i, path in enumerate(videos):\n",
    "    # read video\n",
    "        video = mmcv.VideoReader(os.path.join(dataset, path))\n",
    "        assert video.opened, f'Faild to load video file {path}'\n",
    "\n",
    "        for frame_id, cur_frame in enumerate(mmcv.track_iter_progress(video)):\n",
    "            print(' ({} / {})'.format(i + 1, len(videos)), end=' ')\n",
    "            mmdet_results = inference_detector(det_model, cur_frame)\n",
    "            detect_results = process_mmdet_results(mmdet_results, args_det_cat_id)\n",
    "\n",
    "            hand_results, returned_outputs = inference_top_down_pose_model(\n",
    "            hand_model,\n",
    "            cur_frame,\n",
    "            detect_results,\n",
    "            bbox_thr = args_bbox_thr,\n",
    "            format='xyxy',\n",
    "            dataset=hand_dataset,\n",
    "            dataset_info=hand_dataset_info,\n",
    "            return_heatmap=False,\n",
    "            outputs=None)\n",
    "\n",
    "            if not hand_results:\n",
    "                whole_stop[frame_id] += 1\n",
    "                \n",
    "            # else:\n",
    "            #     cv2.imwrite('moving!'+ str(frame_id) + '.png', cur_frame)\n",
    "\n",
    "def check_tredency(datasets, max_frame):\n",
    "\n",
    "    whole_stop = np.zeros(max_frame)\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        print('\\nnow check from {}'.format(dataset))\n",
    "        video_detect(whole_stop, dataset)\n",
    "\n",
    "    return whole_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('KETI.pkl') and os.path.isfile('AUTSL.pkl'):\n",
    "    print(\"there are already tredency data. load data....\")\n",
    "\n",
    "    with open('KETI.pkl','rb') as f:\n",
    "        KETI_trend = pkl.load(f)\n",
    "\n",
    "    with open('AUTSL.pkl','rb') as f:\n",
    "        AUTSL_trend = pkl.load(f)\n",
    "\n",
    "else:\n",
    "    KETI_trend = check_tredency(KETI_DIR, KETI_max)\n",
    "    AUTSL_trend = check_tredency(AUTSL_DIR, AUTSL_max)\n",
    "\n",
    "    with open('KETI.pkl','wb') as f:\n",
    "        pkl.dump(KETI_trend,f)\n",
    "\n",
    "    with open('AUTSL.pkl','wb') as f:\n",
    "        pkl.dump(AUTSL_trend,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('NO MOVE FRAME')\n",
    "plt.hist(AUTSL_trend, color='blue', alpha=0.4, bins=100, range=[0, 100], label='AUTSL', density=False)\n",
    "plt.hist(KETI_trend, color='red', alpha=0.4, bins=100, range=[0, 100], label='KETI', density=False)\n",
    "plt.legend()\n",
    "plt.savefig('none_move_frame.png')\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
